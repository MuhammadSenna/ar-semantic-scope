import streamlit as st
import pandas as pd
import numpy as np
import faiss
import pickle
from sentence_transformers import SentenceTransformer
from datasets import load_dataset
import matplotlib.pyplot as plt
import seaborn as sns
from copy import deepcopy
import os

# Page configuration
st.set_page_config(
    page_title="Arabic QnA Semantic Search",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better Arabic text display
st.markdown("""
<style>
.arabic-text {
    direction: rtl;
    text-align: right;
    font-family: 'Arial Unicode MS', 'Tahoma', sans-serif;
    font-size: 16px;
    line-height: 1.6;
    padding: 10px;
    background-color: #4f5157;
    border-radius: 5px;
    margin: 10px 0;
}

.question-box {
    background-color: #41a5f0;
    border-left: 4px solid #1f77b4;
    padding: 15px;
    margin: 10px 0;
    border-radius: 5px;
}

.answer-box {
    background-color: #45cc45;
    border-left: 4px solid #2ca02c;
    padding: 15px;
    margin: 10px 0;
    border-radius: 5px;
}

.similarity-score {
    background-color: #c7a330;
    border: 1px solid #ffeaa7;
    padding: 5px 10px;
    border-radius: 15px;
    font-weight: bold;
}
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_and_prepare_data():
    """Load and prepare the Arabic QnA dataset"""
    with st.spinner("Loading Arabic QnA dataset..."):
        # Load dataset
        qna_dataset = load_dataset("sadeem-ai/arabic-qna")
        
        # Filter for entries that have answers
        qna_dataset = qna_dataset.filter(lambda x: x["has_answer"] == True)
        
        # Extract text and metadata
        doc_text = list(qna_dataset["train"]["text"])
        questions = list(qna_dataset["train"]["question"])
        answers = list(qna_dataset["train"]["answer"])
        
        metadata = [
            {
                "source": rec["source"],
                "title": rec["title"],
                "question": rec["question"],
                "answer": rec["answer"]
            }
            for rec in qna_dataset["train"]
        ]
        
        return doc_text, metadata, questions, answers, qna_dataset

@st.cache_resource
def load_model():
    """Load the sentence transformer model"""
    model_id = 'sentence-transformers/distiluse-base-multilingual-cased-v2'
    try:
        model = SentenceTransformer(model_id)
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

@st.cache_data
def create_embeddings_and_index(_model, doc_text):
    """Create embeddings and FAISS index"""
    with st.spinner("Creating embeddings and search index..."):
        # Create embeddings
        encoded_text = _model.encode(doc_text, show_progress_bar=False)
        
        # Normalize embeddings
        norm_encoded_docs = deepcopy(encoded_text)
        faiss.normalize_L2(norm_encoded_docs)
        
        # Create FAISS index
        dim = encoded_text.shape[1]
        text_ids = np.array([i for i in range(len(doc_text))], dtype=np.int64)
        
        faiss_index = faiss.IndexIDMap(faiss.IndexFlatIP(dim))
        faiss_index.add_with_ids(norm_encoded_docs, text_ids)
        
        return faiss_index, encoded_text

def search_similar_questions(model, faiss_index, query, metadata, top_k=5):
    """Search for similar questions using semantic similarity"""
    # Encode query
    question_embd = model.encode(query)
    question_embd = question_embd.reshape(1, -1)
    faiss.normalize_L2(question_embd)
    
    # Search
    similarities, indices = faiss_index.search(question_embd, top_k)
    
    results = []
    for i, (similarity, idx) in enumerate(zip(similarities[0], indices[0])):
        if idx != -1:  # Valid result
            results.append({
                'rank': i + 1,
                'similarity': float(similarity),
                'question': metadata[idx]['question'],
                'answer': metadata[idx]['answer'],
                'source': metadata[idx]['source'],
                'title': metadata[idx]['title']
            })
    
    return results

def display_search_results(results):
    """Display search results in a formatted way"""
    for result in results:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown(f"""
            <div class="question-box">
                <h4>Ø§Ù„Ø³Ø¤Ø§Ù„ (Question #{result['rank']}):</h4>
                <div class="arabic-text">{result['question']}</div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div class="answer-box">
                <h4>Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Answer):</h4>
                <div class="arabic-text">{result['answer']}</div>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ (Source & Details)"):
                st.write(f"**Ø§Ù„Ù…ØµØ¯Ø± (Source):** {result['source']}")
                st.write(f"**Ø§Ù„Ø¹Ù†ÙˆØ§Ù† (Title):** {result['title']}")
        
        with col2:
            similarity_percentage = result['similarity'] * 100
            st.markdown(f"""
            <div class="similarity-score">
                Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity_percentage:.1f}%
            </div>
            """, unsafe_allow_html=True)
        
        st.divider()

def show_dataset_statistics(qna_dataset, questions, answers):
    """Display dataset statistics"""
    st.subheader("Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Dataset Statistics)")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Total Questions)", len(questions))
    
    with col2:
        avg_question_length = np.mean([len(q.split()) for q in questions])
        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ (Avg Question Length)", f"{avg_question_length:.1f} words")
    
    with col3:
        avg_answer_length = np.mean([len(a.split()) for a in answers])
        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Avg Answer Length)", f"{avg_answer_length:.1f} words")
    
    # Distribution chart
    st.subheader("ØªÙˆØ²ÙŠØ¹ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Sources Distribution)")
    
    sources = [item['source'] for item in qna_dataset['train']]
    source_counts = pd.Series(sources).value_counts()
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x=source_counts.values, y=source_counts.index, ax=ax)
    plt.title('Distribution of Data Sources')
    plt.xlabel('Count')
    plt.ylabel('Source')
    st.pyplot(fig)

def main():
    st.title("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    st.title("Arabic QnA Semantic Search")
    
    st.markdown("""
    Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ³ØªØ®Ø¯Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ.
    
    This application uses AI techniques to search through an Arabic QnA database using semantic similarity.
    """)
    
    # Load data and model
    try:
        doc_text, metadata, questions, answers, qna_dataset = load_and_prepare_data()
        model = load_model()
        
        if model is None:
            st.error("ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
            return
        
        faiss_index, embeddings = create_embeddings_and_index(model, doc_text)
        
        # Sidebar
        with st.sidebar:
            st.header("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø« (Search Settings)")
            
            top_k = st.slider(
                "Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Number of Results)",
                min_value=1,
                max_value=10,
                value=5
            )
            
            st.divider()
            
            show_stats = st.checkbox("Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Show Dataset Statistics)")
            
            if show_stats:
                show_dataset_statistics(qna_dataset, questions, answers)
        
        # Main search interface
        st.subheader("Ø§Ù„Ø¨Ø­Ø« (Search)")
        
        # Example questions
        st.markdown("**Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Example Questions):**")
        example_questions = [
            "Ù…Ø§ Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ ØµØºØ± Ø§Ù„Ø£Ø³Ù†Ø§Ù†",
            "ÙƒÙŠÙ Ø£ØªØ¹Ù„Ù… Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©",
            "Ù…Ø§ Ù‡ÙŠ ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ø±ÙŠØ§Ø¶Ø©",
            "ÙƒÙŠÙ Ø£Ø­Ø³Ù† Ù…Ù† ØµØ­ØªÙŠ"
        ]
        
        cols = st.columns(len(example_questions))
        for i, example in enumerate(example_questions):
            if cols[i].button(example, key=f"example_{i}"):
                st.session_state.search_query = example
        
        # Search input
        search_query = st.text_input(
            "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ (Enter your question here):",
            value=st.session_state.get('search_query', ''),
            placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ ØµØºØ± Ø§Ù„Ø£Ø³Ù†Ø§Ù†ØŸ"
        )
        
        if st.button("Ø¨Ø­Ø« (Search)", type="primary") or search_query:
            if search_query.strip():
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«... (Searching...)"):
                    results = search_similar_questions(
                        model, faiss_index, search_query, metadata, top_k
                    )
                    
                    if results:
                        st.success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(results)} Ù†ØªÙŠØ¬Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©")
                        st.markdown("---")
                        display_search_results(results)
                    else:
                        st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…Ø´Ø§Ø¨Ù‡Ø©")
            else:
                st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„ Ù„Ù„Ø¨Ø­Ø«")
                
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
        st.markdown("""
        **Ø­Ù„ÙˆÙ„ Ù…Ù‚ØªØ±Ø­Ø©:**
        1. ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
        2. Ø£Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        3. ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ù…Ø³Ø§Ø­Ø© ÙƒØ§ÙÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ Ø§Ù„ØµÙ„Ø¨
        """)

if __name__ == "__main__":
    main()